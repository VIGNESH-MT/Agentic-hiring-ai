{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "664f5672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added: C:\\Users\\VigneshMurugesan\\Desktop\\Beta\\resume-ai\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root added:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ff1b91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/VigneshMurugesan/.cache/kagglehub/datasets/arbazkhan971/allskillandnonskill/versions/2/skills.csv')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "\n",
    "taxonomy_path = kagglehub.dataset_download(\n",
    "    \"arbazkhan971/allskillandnonskill\"\n",
    ")\n",
    "taxonomy_path = Path(taxonomy_path)\n",
    "\n",
    "taxonomy_csv = next(taxonomy_path.glob(\"*.csv\"))\n",
    "taxonomy_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f8d15a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxonomy columns: ['Skill']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supply chain engineering\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bullet\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commutations\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pay equity\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>student retention\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Skill\n",
       "0  supply chain engineering\\n\n",
       "1                    bullet\\n\n",
       "2              commutations\\n\n",
       "3                pay equity\\n\n",
       "4         student retention\\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tax = pd.read_csv(taxonomy_csv)\n",
    "print(\"Taxonomy columns:\", df_tax.columns.tolist())\n",
    "df_tax.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8be81c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/VigneshMurugesan/.cache/kagglehub/datasets/asaniczka/data-science-job-postings-and-skills/versions/2/job_postings.csv')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_ds_path = kagglehub.dataset_download(\n",
    "    \"asaniczka/data-science-job-postings-and-skills\"\n",
    ")\n",
    "ml_ds_path = Path(ml_ds_path)\n",
    "\n",
    "ml_ds_csv = next(ml_ds_path.glob(\"*.csv\"))\n",
    "ml_ds_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33655a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML/DS columns: ['job_link', 'last_processed_time', 'last_status', 'got_summary', 'got_ner', 'is_being_worked', 'job_title', 'company', 'job_location', 'first_seen', 'search_city', 'search_country', 'search_position', 'job_level', 'job_type']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>last_processed_time</th>\n",
       "      <th>last_status</th>\n",
       "      <th>got_summary</th>\n",
       "      <th>got_ner</th>\n",
       "      <th>is_being_worked</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-mach...</td>\n",
       "      <td>2024-01-21 08:08:48.031964+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>East Haven</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/principal-s...</td>\n",
       "      <td>2024-01-20 04:02:12.331406+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>El Cerrito</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-etl-...</td>\n",
       "      <td>2024-01-21 08:08:31.941595+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior ETL Data Warehouse Specialist</td>\n",
       "      <td>Adame Services LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>Middletown</td>\n",
       "      <td>United States</td>\n",
       "      <td>Technical Support Specialist</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>2024-01-20 15:30:55.796572+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior Data Warehouse Developer / Architect</td>\n",
       "      <td>Morph Enterprise</td>\n",
       "      <td>Harrisburg, PA</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>United States</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-data-e...</td>\n",
       "      <td>2024-01-21 08:08:58.312124+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Dice</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maintenance Data Analyst</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/senior-mach...   \n",
       "1  https://www.linkedin.com/jobs/view/principal-s...   \n",
       "2  https://www.linkedin.com/jobs/view/senior-etl-...   \n",
       "3  https://www.linkedin.com/jobs/view/senior-data...   \n",
       "4  https://www.linkedin.com/jobs/view/lead-data-e...   \n",
       "\n",
       "             last_processed_time   last_status got_summary got_ner  \\\n",
       "0  2024-01-21 08:08:48.031964+00  Finished NER           t       t   \n",
       "1  2024-01-20 04:02:12.331406+00  Finished NER           t       t   \n",
       "2  2024-01-21 08:08:31.941595+00  Finished NER           t       t   \n",
       "3  2024-01-20 15:30:55.796572+00  Finished NER           t       t   \n",
       "4  2024-01-21 08:08:58.312124+00  Finished NER           t       t   \n",
       "\n",
       "  is_being_worked                                     job_title  \\\n",
       "0               f              Senior Machine Learning Engineer   \n",
       "1               f  Principal Software Engineer, ML Accelerators   \n",
       "2               f          Senior ETL Data Warehouse Specialist   \n",
       "3               f   Senior Data Warehouse Developer / Architect   \n",
       "4               f                            Lead Data Engineer   \n",
       "\n",
       "              company       job_location  first_seen search_city  \\\n",
       "0   Jobs for Humanity      New Haven, CT  2024-01-14  East Haven   \n",
       "1              Aurora  San Francisco, CA  2024-01-14  El Cerrito   \n",
       "2  Adame Services LLC       New York, NY  2024-01-14  Middletown   \n",
       "3    Morph Enterprise     Harrisburg, PA  2024-01-12     Lebanon   \n",
       "4                Dice          Plano, TX  2024-01-14    McKinney   \n",
       "\n",
       "  search_country                 search_position   job_level job_type  \n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite  \n",
       "1  United States                  Set-Key Driver  Mid senior   Onsite  \n",
       "2  United States    Technical Support Specialist   Associate   Onsite  \n",
       "3  United States                       Architect  Mid senior   Onsite  \n",
       "4  United States        Maintenance Data Analyst  Mid senior   Onsite  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml = pd.read_csv(ml_ds_csv)\n",
    "print(\"ML/DS columns:\", df_ml.columns.tolist())\n",
    "df_ml.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc0d4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.skills_ingestion import (\n",
    "    load_resume_skills,\n",
    "    load_taxonomy_skills,\n",
    "    load_ml_ds_skills,\n",
    "    build_unified_skills_catalog\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5479c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.skills_normalizer import normalize_skill\n",
    "from pathlib import Path\n",
    "\n",
    "def load_taxonomy_skills(csv_path: Path) -> set[str]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    print(\"DEBUG: taxonomy columns =\", df.columns.tolist())\n",
    "\n",
    "    # Hard, explicit handling for this dataset (enterprise-safe)\n",
    "    if \"Skill\" in df.columns:\n",
    "        skill_col = \"Skill\"\n",
    "    elif \"skill\" in df.columns:\n",
    "        skill_col = \"skill\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"❌ Cannot find Skill column. Columns found: {df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    skills = (\n",
    "        df[skill_col]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.strip()\n",
    "        .apply(normalize_skill)\n",
    "    )\n",
    "\n",
    "    return set(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "656644b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_link',\n",
       " 'last_processed_time',\n",
       " 'last_status',\n",
       " 'got_summary',\n",
       " 'got_ner',\n",
       " 'is_being_worked',\n",
       " 'job_title',\n",
       " 'company',\n",
       " 'job_location',\n",
       " 'first_seen',\n",
       " 'search_city',\n",
       " 'search_country',\n",
       " 'search_position',\n",
       " 'job_level',\n",
       " 'job_type']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ml = pd.read_csv(ml_ds_csv)\n",
    "df_ml.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.skills_normalizer import normalize_skill\n",
    "\n",
    "def load_ml_ds_skills(csv_path: Path) -> set[str]:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    print(\"DEBUG: ML/DS columns =\", df.columns.tolist())\n",
    "\n",
    "    # Use job titles as a proxy for skills (industry-accepted approach)\n",
    "    if \"job_title\" not in df.columns:\n",
    "        raise ValueError(\n",
    "            f\"job_title column not found. Available columns: {df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    raw_titles = (\n",
    "        df[\"job_title\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[^a-z0-9 ]\", \" \", regex=True)\n",
    "    )\n",
    "\n",
    "    # Tokenize titles into candidate skills\n",
    "    tokens = (\n",
    "        raw_titles\n",
    "        .str.split()\n",
    "        .explode()\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    # Filter to meaningful ML/DS tokens\n",
    "    allowed_tokens = {\n",
    "        \"data\", \"scientist\", \"science\", \"ml\", \"ai\", \"engineer\",\n",
    "        \"analytics\", \"analyst\", \"machine\", \"learning\", \"deep\",\n",
    "        \"research\", \"nlp\", \"cv\"\n",
    "    }\n",
    "\n",
    "    skills = (\n",
    "        tokens[tokens.isin(allowed_tokens)]\n",
    "        .apply(normalize_skill)\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    return set(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eae5d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: taxonomy columns = ['Skill']\n",
      "DEBUG: ML/DS columns = ['job_link', 'last_processed_time', 'last_status', 'got_summary', 'got_ner', 'is_being_worked', 'job_title', 'company', 'job_location', 'first_seen', 'search_city', 'search_country', 'search_position', 'job_level', 'job_type']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n❌ Could not infer skills column in ML/DS dataset.\n\nAvailable columns:\n['job_link', 'last_processed_time', 'last_status', 'got_summary', 'got_ner', 'is_being_worked', 'job_title', 'company', 'job_location', 'first_seen', 'search_city', 'search_country', 'search_position', 'job_level', 'job_type']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m taxonomy_skills = load_taxonomy_skills(taxonomy_csv)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ml_ds_skills = \u001b[43mload_ml_ds_skills\u001b[49m\u001b[43m(\u001b[49m\u001b[43mml_ds_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mlen\u001b[39m(taxonomy_skills), \u001b[38;5;28mlen\u001b[39m(ml_ds_skills)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mload_ml_ds_skills\u001b[39m\u001b[34m(csv_path)\u001b[39m\n\u001b[32m     25\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m skills_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     29\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m❌ Could not infer skills column in ML/DS dataset.\u001b[39m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[33mAvailable columns:\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mdf.columns.tolist()\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     35\u001b[39m         )\n\u001b[32m     37\u001b[39m     skills = (\n\u001b[32m     38\u001b[39m         df[skills_col]\n\u001b[32m     39\u001b[39m         .dropna()\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m         .apply(normalize_skill)\n\u001b[32m     47\u001b[39m     )\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(skills)\n",
      "\u001b[31mValueError\u001b[39m: \n❌ Could not infer skills column in ML/DS dataset.\n\nAvailable columns:\n['job_link', 'last_processed_time', 'last_status', 'got_summary', 'got_ner', 'is_being_worked', 'job_title', 'company', 'job_location', 'first_seen', 'search_city', 'search_country', 'search_position', 'job_level', 'job_type']\n"
     ]
    }
   ],
   "source": [
    "taxonomy_skills = load_taxonomy_skills(taxonomy_csv)\n",
    "ml_ds_skills = load_ml_ds_skills(ml_ds_csv)\n",
    "\n",
    "len(taxonomy_skills), len(ml_ds_skills)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
